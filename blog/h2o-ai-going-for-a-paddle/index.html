<!DOCTYPE html>
<html lang="en-US"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>H2O.ai: Going for a Paddle – Bath Machine Learning Meetup</title><link rel="dns-prefetch" href="//fonts.googleapis.com"><link rel="dns-prefetch" href="//s.w.org"><script type="text/javascript" data-cfasync="false">
	var em_version         = '6.0.2';
	var em_track_user      = true;
	var em_no_track_reason = '';
	
	var disableStr = 'ga-disable-UA-172994224-1';

	/* Function to detect opted out users */
	function __gaTrackerIsOptedOut() {
		return document.cookie.indexOf(disableStr + '=true') > -1;
	}

	/* Disable tracking if the opt-out cookie exists. */
	if ( __gaTrackerIsOptedOut() ) {
		window[disableStr] = true;
	}

	/* Opt-out function */
	function __gaTrackerOptout() {
	  document.cookie = disableStr + '=true; expires=Thu, 31 Dec 2099 23:59:59 UTC; path=/';
	  window[disableStr] = true;
	}

	if ( 'undefined' === typeof gaOptout ) {
		function gaOptout() {
			__gaTrackerOptout();
		}
	}
	
	if ( em_track_user ) {
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','__gaTracker');

window.ga = __gaTracker;		__gaTracker('create', 'UA-172994224-1', 'auto');
		__gaTracker('set', 'forceSSL', true);
		__gaTracker('send','pageview');
		__gaTracker( function() { window.ga = __gaTracker; } );
	} else {
		console.log( "" );
		(function() {
			/* https://developers.google.com/analytics/devguides/collection/analyticsjs/ */
			var noopfn = function() {
				return null;
			};
			var noopnullfn = function() {
				return null;
			};
			var Tracker = function() {
				return null;
			};
			var p = Tracker.prototype;
			p.get = noopfn;
			p.set = noopfn;
			p.send = noopfn;
			var __gaTracker = function() {
				var len = arguments.length;
				if ( len === 0 ) {
					return;
				}
				var f = arguments[len-1];
				if ( typeof f !== 'object' || f === null || typeof f.hitCallback !== 'function' ) {
					console.log( 'Not running function __gaTracker(' + arguments[0] + " ....) because you are not being tracked. " + em_no_track_reason );
					return;
				}
				try {
					f.hitCallback();
				} catch (ex) {

				}
			};
			__gaTracker.create = function() {
				return new Tracker();
			};
			__gaTracker.getByName = noopnullfn;
			__gaTracker.getAll = function() {
				return [];
			};
			__gaTracker.remove = noopfn;
			window['__gaTracker'] = __gaTracker;
			window.ga = __gaTracker;		})();
		}
</script><link rel="stylesheet" id="wp-block-library-css" href="https://bathml.github.io/inc/css/dist/block-library/style.min.css" type="text/css" media="all"><link rel="stylesheet" id="font-awesome-5-css" href="https://bathml.github.io/wp-content/plugins/themeisle-companion/obfx_modules/gutenberg-blocks/assets/fontawesome/css/all.min.css" type="text/css" media="all"><link rel="stylesheet" id="font-awesome-4-shims-css" href="https://bathml.github.io/wp-content/plugins/themeisle-companion/obfx_modules/gutenberg-blocks/assets/fontawesome/css/v4-shims.min.css" type="text/css" media="all"><link rel="stylesheet" id="themeisle-block_styles-css" href="https://bathml.github.io/wp-content/plugins/themeisle-companion/vendor/codeinwp/gutenberg-blocks/build/style.css" type="text/css" media="all"><link rel="stylesheet" id="hestia-clients-bar-css" href="https://bathml.github.io/wp-content/plugins/themeisle-companion/obfx_modules/companion-legacy/assets/css/hestia/clients-bar.css" type="text/css" media="all"><link rel="stylesheet" id="bootstrap-css" href="https://bathml.github.io/themes/hestia/assets/bootstrap/css/bootstrap.min.css" type="text/css" media="all"><link rel="stylesheet" id="hestia-font-sizes-css" href="https://bathml.github.io/themes/hestia/assets/css/font-sizes.min.css" type="text/css" media="all"><link rel="stylesheet" id="hestia_style-css" href="https://bathml.github.io/themes/hestia/style.min.css" type="text/css" media="all"><style id="hestia_style-inline-css" type="text/css">
.hestia-top-bar, .hestia-top-bar .widget.widget_shopping_cart .cart_list {
			background-color: #363537
		}
		.hestia-top-bar .widget .label-floating input[type=search]:-webkit-autofill {
			-webkit-box-shadow: inset 0 0 0px 9999px #363537
		}.hestia-top-bar, .hestia-top-bar .widget .label-floating input[type=search], .hestia-top-bar .widget.widget_search form.form-group:before, .hestia-top-bar .widget.widget_product_search form.form-group:before, .hestia-top-bar .widget.widget_shopping_cart:before {
			color: #ffffff
		} 
		.hestia-top-bar .widget .label-floating input[type=search]{
			-webkit-text-fill-color:#ffffff !important 
		}.hestia-top-bar a, .hestia-top-bar .top-bar-nav li a {
			color: #ffffff
		}.hestia-top-bar a:hover, .hestia-top-bar .top-bar-nav li a:hover {
			color: #eeeeee
		}
	
		a, 
		.navbar .dropdown-menu li:hover > a,
		.navbar .dropdown-menu li:focus > a,
		.navbar .dropdown-menu li:active > a,
		.navbar .navbar-nav > li .dropdown-menu li:hover > a,
		body:not(.home) .navbar-default .navbar-nav > .active:not(.btn) > a,
		body:not(.home) .navbar-default .navbar-nav > .active:not(.btn) > a:hover,
		body:not(.home) .navbar-default .navbar-nav > .active:not(.btn) > a:focus,
		a:hover, 
		.card-blog a.moretag:hover, 
		.card-blog a.more-link:hover, 
		.widget a:hover,
		.has-text-color.has-accent-color,
		p.has-text-color a {
		    color:#e91e63;
		}
		
		.pagination span.current, .pagination span.current:focus, .pagination span.current:hover {
			border-color:#e91e63
		}
		
		button,
		button:hover,
		.woocommerce .track_order button[type="submit"],
		.woocommerce .track_order button[type="submit"]:hover,
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit,
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit:hover,
		input[type="button"],
		input[type="button"]:hover,
		input[type="submit"],
		input[type="submit"]:hover,
		input#searchsubmit, 
		.pagination span.current, 
		.pagination span.current:focus, 
		.pagination span.current:hover,
		.btn.btn-primary,
		.btn.btn-primary:link,
		.btn.btn-primary:hover, 
		.btn.btn-primary:focus, 
		.btn.btn-primary:active, 
		.btn.btn-primary.active, 
		.btn.btn-primary.active:focus, 
		.btn.btn-primary.active:hover,
		.btn.btn-primary:active:hover, 
		.btn.btn-primary:active:focus, 
		.btn.btn-primary:active:hover,
		.hestia-sidebar-open.btn.btn-rose,
		.hestia-sidebar-close.btn.btn-rose,
		.hestia-sidebar-open.btn.btn-rose:hover,
		.hestia-sidebar-close.btn.btn-rose:hover,
		.hestia-sidebar-open.btn.btn-rose:focus,
		.hestia-sidebar-close.btn.btn-rose:focus,
		.label.label-primary,
		.hestia-work .portfolio-item:nth-child(6n+1) .label,
		.nav-cart .nav-cart-content .widget .buttons .button,
		.has-accent-background-color[class*="has-background"] {
		    background-color: #e91e63;
		}
		
		@media (max-width: 768px) { 
	
			.navbar-default .navbar-nav>li>a:hover,
			.navbar-default .navbar-nav>li>a:focus,
			.navbar .navbar-nav .dropdown .dropdown-menu li a:hover,
			.navbar .navbar-nav .dropdown .dropdown-menu li a:focus,
			.navbar button.navbar-toggle:hover,
			.navbar .navbar-nav li:hover > a i {
			    color: #e91e63;
			}
		}
		
		body:not(.woocommerce-page) button:not([class^="fl-"]):not(.hestia-scroll-to-top):not(.navbar-toggle):not(.close),
		body:not(.woocommerce-page) .button:not([class^="fl-"]):not(hestia-scroll-to-top):not(.navbar-toggle):not(.add_to_cart_button),
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit,
		input[type="submit"], 
		input[type="button"], 
		.btn.btn-primary,
		.widget_product_search button[type="submit"],
		.hestia-sidebar-open.btn.btn-rose,
		.hestia-sidebar-close.btn.btn-rose,
		.everest-forms button[type=submit].everest-forms-submit-button {
		    -webkit-box-shadow: 0 2px 2px 0 rgba(233,30,99,0.14),0 3px 1px -2px rgba(233,30,99,0.2),0 1px 5px 0 rgba(233,30,99,0.12);
		    box-shadow: 0 2px 2px 0 rgba(233,30,99,0.14),0 3px 1px -2px rgba(233,30,99,0.2),0 1px 5px 0 rgba(233,30,99,0.12);
		}
		
		.card .header-primary, .card .content-primary,
		.everest-forms button[type=submit].everest-forms-submit-button {
		    background: #e91e63;
		}
		
		body:not(.woocommerce-page) .button:not([class^="fl-"]):not(.hestia-scroll-to-top):not(.navbar-toggle):not(.add_to_cart_button):hover,
		body:not(.woocommerce-page) button:not([class^="fl-"]):not(.hestia-scroll-to-top):not(.navbar-toggle):not(.close):hover,
		div.wpforms-container .wpforms-form button[type=submit].wpforms-submit:hover,
		input[type="submit"]:hover,
		input[type="button"]:hover,
		input#searchsubmit:hover, 
		.widget_product_search button[type="submit"]:hover,
		.pagination span.current, 
		.btn.btn-primary:hover, 
		.btn.btn-primary:focus, 
		.btn.btn-primary:active, 
		.btn.btn-primary.active, 
		.btn.btn-primary:active:focus, 
		.btn.btn-primary:active:hover, 
		.hestia-sidebar-open.btn.btn-rose:hover,
		.hestia-sidebar-close.btn.btn-rose:hover,
		.pagination span.current:hover,
		.everest-forms button[type=submit].everest-forms-submit-button:hover,
 		.everest-forms button[type=submit].everest-forms-submit-button:focus,
 		.everest-forms button[type=submit].everest-forms-submit-button:active {
			-webkit-box-shadow: 0 14px 26px -12px rgba(233,30,99,0.42),0 4px 23px 0 rgba(0,0,0,0.12),0 8px 10px -5px rgba(233,30,99,0.2);
		    box-shadow: 0 14px 26px -12px rgba(233,30,99,0.42),0 4px 23px 0 rgba(0,0,0,0.12),0 8px 10px -5px rgba(233,30,99,0.2);
			color: #fff;
		}
		
		.form-group.is-focused .form-control {
			background-image: -webkit-gradient(linear,left top, left bottom,from(#e91e63),to(#e91e63)),-webkit-gradient(linear,left top, left bottom,from(#d2d2d2),to(#d2d2d2));
			background-image: -webkit-linear-gradient(linear,left top, left bottom,from(#e91e63),to(#e91e63)),-webkit-linear-gradient(linear,left top, left bottom,from(#d2d2d2),to(#d2d2d2));
			background-image: linear-gradient(linear,left top, left bottom,from(#e91e63),to(#e91e63)),linear-gradient(linear,left top, left bottom,from(#d2d2d2),to(#d2d2d2));
		}
		
		.navbar:not(.navbar-transparent) li:not(.btn):hover > a,
		.navbar li.on-section:not(.btn) > a, 
		.navbar.full-screen-menu.navbar-transparent li:not(.btn):hover > a,
		.navbar.full-screen-menu .navbar-toggle:hover,
		.navbar:not(.navbar-transparent) .nav-cart:hover, 
		.navbar:not(.navbar-transparent) .hestia-toggle-search:hover {
				color:#e91e63}
		
		.has-text-color.has-background-color-color { color: #E5E5E5; }
		.has-background-color-background-color[class*="has-background"] { background-color: #E5E5E5; }
		
.btn.btn-primary:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item), input[type="submit"]:not(.search-submit), body:not(.woocommerce-account) .woocommerce .button.woocommerce-Button, .woocommerce .product button.button, .woocommerce .product button.button.alt, .woocommerce .product #respond input#submit, .woocommerce-cart .blog-post .woocommerce .cart-collaterals .cart_totals .checkout-button, .woocommerce-checkout #payment #place_order, .woocommerce-account.woocommerce-page button.button, .woocommerce .track_order button[type="submit"], .nav-cart .nav-cart-content .widget .buttons .button, .woocommerce a.button.wc-backward, body.woocommerce .wccm-catalog-item a.button, body.woocommerce a.wccm-button.button, form.woocommerce-form-coupon button.button, div.wpforms-container .wpforms-form button[type=submit].wpforms-submit, div.woocommerce a.button.alt, div.woocommerce table.my_account_orders .button, .btn.colored-button, .btn.btn-left, .btn.btn-right, .btn:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item):not(.hestia-sidebar-open):not(.hestia-sidebar-close){ padding-top:15px;  padding-bottom:15px;  padding-left:33px;  padding-right:33px; }
.btn.btn-primary:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item), input[type="submit"]:not(.search-submit), body:not(.woocommerce-account) .woocommerce .button.woocommerce-Button, .woocommerce .product button.button, .woocommerce .product button.button.alt, .woocommerce .product #respond input#submit, .woocommerce-cart .blog-post .woocommerce .cart-collaterals .cart_totals .checkout-button, .woocommerce-checkout #payment #place_order, .woocommerce-account.woocommerce-page button.button, .woocommerce .track_order button[type="submit"], .nav-cart .nav-cart-content .widget .buttons .button, .woocommerce a.button.wc-backward, body.woocommerce .wccm-catalog-item a.button, body.woocommerce a.wccm-button.button, form.woocommerce-form-coupon button.button, div.wpforms-container .wpforms-form button[type=submit].wpforms-submit, div.woocommerce a.button.alt, div.woocommerce table.my_account_orders .button, input[type="submit"].search-submit, .hestia-view-cart-wrapper .added_to_cart.wc-forward, .woocommerce-product-search button, .woocommerce-cart .actions .button, #secondary div[id^=woocommerce_price_filter] .button, .woocommerce div[id^=woocommerce_widget_cart].widget .buttons .button, .searchform input[type=submit], .searchform button, .search-form:not(.media-toolbar-primary) input[type=submit], .search-form:not(.media-toolbar-primary) button, .woocommerce-product-search input[type=submit], .btn.colored-button, .btn.btn-left, .btn.btn-right, .btn:not(.colored-button):not(.btn-left):not(.btn-right):not(.btn-just-icon):not(.menu-item):not(.hestia-sidebar-open):not(.hestia-sidebar-close){border-radius:3px;}
@media (min-width: 769px){
			.page-header.header-small .hestia-title,
			.page-header.header-small .title,
			h1.hestia-title.title-in-content,
			.main article.section .has-title-font-size {
				font-size: 42px;
			}}

		.page-template-builder-fullwidth-std .header > .elementor {
			padding-top: 70px;
		}

</style><link rel="stylesheet" id="font-awesome-5-all-css" href="https://bathml.github.io/themes/hestia/assets/font-awesome/css/all.min.css" type="text/css" media="all"><link rel="stylesheet" id="font-awesome-4-shim-css" href="https://bathml.github.io/themes/hestia/assets/font-awesome/css/v4-shims.min.css" type="text/css" media="all"><link rel="stylesheet" id="hestia_fonts-css" href="https://fonts.googleapis.com/css?family=Roboto%3A300%2C400%2C500%2C700%7CRoboto+Slab%3A400%2C700&subset=latin%2Clatin-ext&ver=2.5.6" type="text/css" media="all"><script type="text/javascript">
/* <![CDATA[ */
var exactmetrics_frontend = {"js_events_tracking":"true","download_extensions":"zip,mp3,mpeg,pdf,docx,pptx,xlsx,rar","inbound_paths":"[{\"path\":\"\\\/go\\\/\",\"label\":\"affiliate\"},{\"path\":\"\\\/recommend\\\/\",\"label\":\"affiliate\"}]","home_url":"https:\/\/PLACEHOLDER.wpsho","hash_tracking":"false"};
/* ]]> */
</script><script type="text/javascript" src="https://bathml.github.io/wp-content/plugins/google-analytics-dashboard-for-wp/assets/js/frontend.min.js"></script><script type="text/javascript" src="https://bathml.github.io/inc/js/jquery/jquery.js"></script><script type="text/javascript" src="https://bathml.github.io/inc/js/jquery/jquery-migrate.min.js"></script><link rel="icon" href="https://bathml.github.io/assets/2018/11/cropped-square_large_black-32x32.png" sizes="32x32"><link rel="icon" href="https://bathml.github.io/assets/2018/11/cropped-square_large_black-192x192.png" sizes="192x192"><link rel="apple-touch-icon-precomposed" href="https://bathml.github.io/assets/2018/11/cropped-square_large_black-180x180.png"><meta name="msapplication-TileImage" content="https://bathml.github.io/assets/2018/11/cropped-square_large_black-270x270.png"></head><body class="post-template-default single single-post postid-167 single-format-standard wp-custom-logo blog-post header-layout-default">
		<div class="wrapper post-167 post type-post status-publish format-standard has-post-thumbnail hentry category-technical tag-frameworks tag-h2o tag-machinelearning tag-neuralnets tag-randomforest default ">
		<header class="header "><div style="display: none"></div>		<nav class="navbar navbar-default navbar-fixed-top  hestia_left navbar-not-transparent"><div class="container">
						<div class="navbar-header">
			<div class="title-logo-wrapper">
				<a class="navbar-brand" href="https://bathml.github.io/" title="Bath Machine Learning Meetup">
					<img src="https://bathml.github.io/assets/2018/11/cropped-bathml_large_black-1.png" alt="Bath Machine Learning Meetup"></a>
			</div>
								<div class="navbar-toggle-wrapper">
						<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navigation">
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="sr-only">Toggle Navigation</span>
			</button>
					</div>
				</div>
		<div id="main-navigation" class="collapse navbar-collapse"><ul id="menu-top-menu" class="nav navbar-nav"><li id="menu-item-30" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-30"><a title="Home" href="https://bathml.github.io/">Home</a></li>
<li id="menu-item-37" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-37"><a title="Events" href="https://bathml.github.io/events/">Events</a></li>
<li id="menu-item-32" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-32"><a title="Blog" href="https://bathml.github.io/blog/">Blog</a></li>
<li id="menu-item-64" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-64"><a title="Sponsors" href="https://bathml.github.io/sponsors/">Sponsors</a></li>
<li id="menu-item-33" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-33"><a title="Contact" href="https://bathml.github.io/contact/">Contact</a></li>
</ul></div>			</div>
					</nav></header><div id="primary" class="boxed-layout-header page-header header-small" data-parallax="active"><div class="container"><div class="row"><div class="col-md-10 col-md-offset-1 text-center"><h1 class="hestia-title entry-title">H2O.ai: Going for a Paddle</h1><h4 class="author">Published by <a href="https://bathml.github.io/blog/author/owen/" class="vcard author"><strong class="fn">Owen</strong></a> on <time class="entry-date published" datetime="2019-01-29T18:28:00+00:00" content="2019-01-29">January 29, 2019</time><time class="updated hestia-hidden" datetime="2019-01-29T18:28:22+00:00">January 29, 2019</time></h4></div></div></div><div class="header-filter" style="background-image: url(https://bathml.github.io/assets/2019/01/h2oai-going-for-a-paddle.png);"></div></div>
<div class="main  main-raised ">
	<div class="blog-post blog-post-wrapper">
		<div class="container">
			<article id="post-167" class="section section-text"><div class="row">
				<div class="col-md-8 single-post-container col-md-offset-2" data-layout="full-width">

			<div class="single-post-wrap entry-content">
<p>This post was written in August 2017, shortly after I started my placement year at Mango Solutions. It was originally published on the <a href="https://www.mango-solutions.com/blog/h2o-ai-going-for-a-paddle">Mango blog,</a> and they have kindly allowed us to repost it here!</p>



<hr class="wp-block-separator"><p><em><strong>A quick disclaimer: </strong>This post isn't called H2O.ai: Going for the 100m freestyle world record. I'm not trying to win a Kaggle competition. I'm not carrying out detailed, highly-controlled benchmarking tests. I'm not, in fact, claiming to be doing anything particularly useful at all. This is <a href="#justme">just me</a>, just playing around with some code, just for the fun of it.</em></p>
<div id="h-to-o-dot-what" class="section level2">
<h2>H-to-O dot <em>what</em>?</h2>
<p>"I've never even heard of that," you might be thinking. Well, don't worry – neither had I until very recently. Let's start by having a look at their website.</p>
<blockquote><p>H2O is the world's leading open source deep learning platform. H2O is used by over 100,000 data scientists and more than 10,000 organizations around the world. – <strong><a class="uri" href="https://www.mango-solutions.com/blog/admin/pages/blog/www.h2o.ai">www.h2o.ai</a></strong></p></blockquote>
<p>In other words, H2O – which has been around since way back in 2011 – is a widely-used platform for carrying out machine learning and data analysis, which is optimised for working wth large datasets.</p>
<p>The primary focus really is on the machine learning. There is a wide selection of algorithms to choose from, ranging from random forests and neural networks to PCA and Word2vec (a full list can be found <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html">in the documentation</a>).</p>
<p>H2O is a language in its own right, although under the hood it is largely written in Java. This makes it incredibly flexible: you can use it with R or Python, link into Spark and Hadoop, or use the built-in "Flow" interface. I'll cover some of this functionality in the rest of this post.</p>
</div>
<div id="demo-random-forest" class="section level2">
<h2>Demo: Random Forest</h2>
<p>Let's test out a couple of H2O's algorithms. To start with, we'll use a random forest for a classification task.</p>
<p>I'm going to use the <a href="http://archive.ics.uci.edu/ml/datasets/Covertype">"Covertype" dataset</a> from the UCI ML datasets archive. This dataset contains nearly 600000 records representing different locations in the USA. The challenge is to predict tree cover type (spruce/fir, pine, aspen etc.) using only cartographic variables (elevation, slope, soil type etc.).</p>
<p>So effectively, the plan is to use a random forest to classify... yep, random forests.</p>
<div id="data-import" class="section level3">
<h3>Data import</h3>
<p>Without further ado, let's get the data into R and have a look at it. <em>Note: for now, I'm going to be using the R interface to H2O, but later we'll try out the Flow interface too.</em></p>
<pre class="r"><code># Load some packages for data manipulation
library(dplyr)
library(readr)

# Data from http://archive.ics.uci.edu/ml/datasets/Covertype
covtype <- read_csv("~/H2O_exploration/covtype.csv", col_names = FALSE) %>%
# Convert some columns to factor
mutate_at(11:55, funs(factor(.)))

# Have a look at what we've got
str(covtype)</code></pre>
<pre><code>## Classes 'tbl_df', 'tbl' and 'data.frame': 581012 obs. of 55 variables:
## $ X1 : int 2596 2590 2804 2785 2595 2579 2606 2605 2617 2612 ...
## $ X2 : int 51 56 139 155 45 132 45 49 45 59 ...
## [... more columns...]
## $ X10: int 6279 6225 6121 6211 6172 6031 6256 6228 6244 6230 ...
## $ X11: Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
## [... loads more columns...]
## $ X54: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
## $ X55: Factor w/ 7 levels "1","2","3","4",..: 5 5 2 2 5 2 5 5 5 5 ...</code></pre>
<p>An explanation of the dataset is available on the download page. The CSV file itself doesn't contain any column names, and the ones R creates for us aren't particularly helpful; but actually, it won't really matter. We only need to take note of a couple of things:</p>
<ul><li>The first 10 columns are <strong>numeric variables</strong> representing various geographical aspects of the location in question. Average yearly rainfall, degree of slope, number of minutes of sunlight between 3 and 4 o'clock on the second Wednesday of August during a leap year, and so on.</li>
<li>Columns 11-14 are <strong>binary categorical variables</strong> signalling whether the forest is within one of four "Wilderness Areas". So if the forest <em>is</em> in one of these areas, then the column representing that area will contain a 1; otherwise each column will contain a 0.</li>
<li>Columns 15-54 are binary categorical variables representing soil type: i.e. Column 11 is storing the answer to "is this area Soil Type 1?", where the answers "yes" or "no" are represented by 1 or 0 respectively. So each record has a 1 in precisely one of these columns, and 0 in the other columns.</li>
<li><strong>Column 55 is the important one</strong>: it's the label indicating what the cover type actually is. This is the <strong>target variable</strong> which we're going to try to predict! There are <strong>7 different possible labels</strong>, representing spruce/fir, aspen, Ponderosa pine etc.</li>
</ul><p>We converted columns 11-55 to factors when we imported the data, so we can crack on with some machine learning right away.</p>
</div>
<div id="the-h2o-r-package" class="section level3">
<h3>The h2o R package</h3>
<p>H2O can be downloaded on its own, but if you're using it with R it's easier to install the <code>h2o</code> package (which is available on CRAN). You'll also need to have Java installed.</p>
<p>Then you can go ahead and load the package into R, and before you can do anything else you'll need to get an H2O cluster up and running using <code>h2o.init()</code>.</p>
<pre class="r"><code>library(h2o)
h2o.init()</code></pre>
<pre><code>## Connection successful!
## 
## R is connected to the H2O cluster: 
## H2O cluster uptime: 2 hours 54 minutes 
## H2O cluster version: 3.10.5.3 
## H2O cluster version age: 1 month and 15 days 
## H2O cluster name: H2O_started_from_R_ojones_mlh028 
## H2O cluster total nodes: 1 
## H2O cluster total memory: 1.50 GB 
## H2O cluster total cores: 4 
## H2O cluster allowed cores: 4 
## H2O cluster healthy: TRUE 
## H2O Connection ip: localhost 
## H2O Connection port: 54321 
## H2O Connection proxy: NA 
## H2O Internal Security: FALSE 
## R Version: R version 3.4.0 (2017-04-21)</code></pre>
<p>This shows us some information about the session we've just created. Notice the cluster is running on a Java Virtual Machine (JVM), and in my case I'm running on 1 node (my laptop) and 4 cores. If you're lucky enough to have a larger setup then you can edit these settings to suit you.</p>
<p>The only function we've used so far gives a good indication of how the package works: the general form of functions is <code>h2o.*(...)</code>, and more often than not the <code>*</code> is replaced by <em>what you would guess you should put there</em>. At first, we want to initialise a cluster, so we use <code>h2o.init</code>. The function names tend to be quite intuitive, so after you've seen them once or twice it's very easy to remember them.</p>
<p>On with the show! Recall that our <code>covtype</code> dataset is currently sitting happily in an R dataframe. However, we're only <em>accessing</em> our H2O cluster through R (remember it's running behind the scenes on a JVM), so we need to pass the data on to the cluster in a format it can work with.</p>
<p>Fortunately this is very easy: <code>as.h2o</code> converts a dataframe to an "H2OFrame". In the R session, it's stored as an environment, but actually this is just a pointer to the data structure which has been created by H2O.</p>
<pre class="r"><code>wet <- as.h2o(covtype)</code></pre>
<p>We're going to want to assess the performance of our random forest once we've trained it, so we'll split our data into training and test sets using <code>h2o.splitFrame</code> – intuitive names, remember?</p>
<pre class="r"><code>wet_split <- h2o.splitFrame(wet, ratios = 0.75, seed = 820)</code></pre>
<p>The observations are randomly divided into sets according to the ratios specfied. Our split is 75:25, but <code>ratios</code> can be a vector too: if, for example, you wanted to create a cross-validation set too, then you could specify <code>ratios = c(0.6, 0.2)</code> to get a 60:20:20 split.</p>
<p>Now we can train our classifier. We want a random forest, so we use – you guessed it – <code>h2o.randomForest</code>. Remember that the label for each observation is in the 55th column, so we set the target variable <code>y</code> to 55. Our training dataframe is the first set from our split data, and then you can include a whole load of other optional parameters. I'm not going to go into huge detail here; I'm just going to set the number of trees to train, and the number of folds for cross-validation. But if you're super keen on making sure your trees are balanced or on fiddling around with per-class sample rates, then rest assured that you can do so. If you don't think balancing trees will do your back any good then fear not: H2O does a pretty good job of using sensible defaults for any parameters you don't explicitly include.</p>
<pre class="r"><code>h2o_rf <- h2o.randomForest(y = 55, training_frame = wet_split[[1]],
ntrees = 1, nfolds = 2)</code></pre>
<p>You might argue that one tree a forest doth not make, and I would agree with you. This is just a demonstration of the syntax – we'll make a proper forest in a minute!</p>
<p>Once the model has finished training, we can calculate some useful performance metrics using <code>h2o.performance</code> – I'm passing in the model we've just trained, and the second part of our dataset (which is our test set).</p>
<pre class="r"><code>h2o.performance(h2o_rf, wet_split[[2]])</code></pre>
<pre><code>## H2OMultinomialMetrics: drf
## 
## Test Set Metrics: 
## =====================
## 
## MSE: (Extract with `h2o.mse`) 0.1253515
## RMSE: (Extract with `h2o.rmse`) 0.3540501
## Logloss: (Extract with `h2o.logloss`) 1.204014
## Mean Per-Class Error: 0.256692
## Confusion Matrix: Extract with `h2o.confusionMatrix(<model>, <data>)`)
## =========================================================================
## Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
## 1 2 3 4 5 6 7 Error Rate
## 1 42484 9651 12 1 98 37 442 0.1942 = 10,241 / 52,725
## 2 5576 64313 457 7 266 268 96 0.0940 = 6,670 / 70,983
## 3 167 526 7609 93 13 469 2 0.1430 = 1,270 / 8,879
## 4 27 34 129 463 1 59 0 0.3506 = 250 / 713
## 5 146 1144 44 0 1030 2 3 0.5652 = 1,339 / 2,369
## 6 114 634 584 40 6 3006 7 0.3154 = 1,385 / 4,391
## 7 557 105 4 1 1 15 4401 0.1343 = 683 / 5,084
## Totals 49071 76407 8839 605 1415 3856 4951 0.1505 = 21,838 / 145,144
## 
## Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>, <data>)`
## =======================================================================
## Top-7 Hit Ratios: 
## k hit_ratio
## 1 1 0.849542
## 2 2 0.969492
## 3 3 0.978669
## 4 4 0.979165
## 5 5 0.979200
## 6 6 0.979200
## 7 7 1.000000</code></pre>
<p>This gives us numeric metrics such as mean square error; a confusion matrix of predicted vs actual classes, with per-class error rates calculated for us; and a "hit ratio table".</p>
<p>For each observation, the classifier works out how likely it is that the observation belongs to each of the 7 classes. This allows it to make a "best guess" at the actual class (which is the "prediction"), but it can also make a second-best guess, a third-best, and so on.</p>
<p><img class="alignnone size-full wp-image-4000" src="https://mango-solutions.com/assets/sites/6/2018/01/image2.png" alt="" width="540" height="123" srcset="https://www.mango-solutions.com/assets/sites/6/2018/01/image2.png 540w,https://www.mango-solutions.com/assets/sites/6/2018/01/image2-300x68.png 300w" sizes="(max-width: 540px) 100vw, 540px"></p>
<div id="demo-random-forest" class="section level2">
<div id="the-h2o-r-package" class="section level3">
<p>The <span class="math inline"><span id="MathJax-Element-1-Frame" class="MathJax" style="font-style: normal;font-weight: normal;line-height: normal;font-size: 16px;text-indent: 0px;text-align: left;letter-spacing: normal;float: none;direction: ltr;max-width: none;max-height: none;min-width: 0px;min-height: 0px;border: 0px;padding: 0px;margin: 0px" role="presentation"><span id="MathJax-Span-1" class="math"><span id="MathJax-Span-2" class="mrow"><span id="MathJax-Span-3" class="mi">k</span></span></span><span class="MJX_Assistive_MathML" role="presentation">k</span></span></span>th row of the hit ratio table gives us the proportion of observations which are correctly classified within the top <span class="math inline"><span id="MathJax-Element-2-Frame" class="MathJax" style="font-style: normal;font-weight: normal;line-height: normal;font-size: 16px;text-indent: 0px;text-align: left;letter-spacing: normal;float: none;direction: ltr;max-width: none;max-height: none;min-width: 0px;min-height: 0px;border: 0px;padding: 0px;margin: 0px" role="presentation"><span id="MathJax-Span-4" class="math"><span id="MathJax-Span-5" class="mrow"><span id="MathJax-Span-6" class="mi">k</span></span></span><span class="MJX_Assistive_MathML" role="presentation">k</span></span></span> guesses the classifier makes. So <span class="math inline"><span id="MathJax-Element-3-Frame" class="MathJax" style="font-style: normal;font-weight: normal;line-height: normal;font-size: 16px;text-indent: 0px;text-align: left;letter-spacing: normal;float: none;direction: ltr;max-width: none;max-height: none;min-width: 0px;min-height: 0px;border: 0px;padding: 0px;margin: 0px" role="presentation"><span id="MathJax-Span-7" class="math"><span id="MathJax-Span-8" class="mrow"><span id="MathJax-Span-9" class="mi">k</span><span id="MathJax-Span-10" class="mo">=</span><span id="MathJax-Span-11" class="mn">1</span></span></span><span class="MJX_Assistive_MathML" role="presentation">k=1</span></span></span> is the accuracy of the classifier – i.e. the proportion of observations which are correctly predicted – <span class="math inline"><span id="MathJax-Element-4-Frame" class="MathJax" style="font-style: normal;font-weight: normal;line-height: normal;font-size: 16px;text-indent: 0px;text-align: left;letter-spacing: normal;float: none;direction: ltr;max-width: none;max-height: none;min-width: 0px;min-height: 0px;border: 0px;padding: 0px;margin: 0px" role="presentation"><span id="MathJax-Span-12" class="math"><span id="MathJax-Span-13" class="mrow"><span id="MathJax-Span-14" class="mi">k</span><span id="MathJax-Span-15" class="mo">=</span><span id="MathJax-Span-16" class="mn">2</span></span></span><span class="MJX_Assistive_MathML" role="presentation">k=2</span></span></span> is the proportion which are within the first two guesses the classifier makes, and so on. The actual class will definitely be in the top 7 guesses (there are only 7 possible classes!) so for <span class="math inline"><span id="MathJax-Element-5-Frame" class="MathJax" style="font-style: normal;font-weight: normal;line-height: normal;font-size: 16px;text-indent: 0px;text-align: left;letter-spacing: normal;float: none;direction: ltr;max-width: none;max-height: none;min-width: 0px;min-height: 0px;border: 0px;padding: 0px;margin: 0px" role="presentation"><span id="MathJax-Span-17" class="math"><span id="MathJax-Span-18" class="mrow"><span id="MathJax-Span-19" class="mi">k</span><span id="MathJax-Span-20" class="mo">=</span><span id="MathJax-Span-21" class="mn">7</span></span></span><span class="MJX_Assistive_MathML" role="presentation">k=7</span></span></span> the hit ratio is 100%.</p>
<p>If your classification task is binomial then you can calculate many other relevant metrics (precision, F1 score, false negative rate etc.) using the selection of <code>h2o.metric</code> functions which are available.</p>
<p>We'll come back to this random forest soon, but first I'm going to have a little look at H2O Flow.</p>
</div>
<div id="h2o-flow" class="section level2">
<h2>H2O Flow</h2>
<p>H2O Flow is H2O's own browser-based interface. Getting started is easy:</p>
<ol><li>Initialise an H2O cluster (e.g. by running <code>h2o.init()</code> in R)</li>
<li>Go to <code>localhost:54321</code> in browser</li>
<li>Unplug keyboard</li>
</ol><p>Honestly. You can do that. You don't need it.</p>
<p><img class="alignnone size-full wp-image-4001" src="https://mango-solutions.com/assets/sites/6/2018/01/image3-1.png" alt="" width="640" height="164" srcset="https://www.mango-solutions.com/assets/sites/6/2018/01/image3-1.png 640w,https://www.mango-solutions.com/assets/sites/6/2018/01/image3-1-300x77.png 300w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>Flow is based on a notebook-style layout. Code is added to cells, which are then run in sequence. You <em>can</em> write raw H2O code yourself, but it's much easier to use the drop-down menus and buttons and let Flow compile the code for you.</p>
<p>The really nice thing about Flow is that it allows you to see exactly what your options are at each stage. When you finish one operation, it gives you a selection of things which you might want to do next. When you are able to change options or parameters, it lists them all out for you so you can <em>see</em> which ones are available and which ones you might want to change.</p>
<p><img class="alignnone size-full wp-image-4002" src="https://mango-solutions.com/assets/sites/6/2018/01/image4-1.gif" alt="" width="800" height="451"></p>
<div id="h2o-flow" class="section level2">
<p>If you like writing code and you already know exactly what you're planning on doing, then the R interface is quicker to use and much more concise. But I'd encourage you to play around with Flow for a while at some point, because you'll probably discover something that you hadn't used before.</p>
<p>Also, it's worth clarifying that when you're using H2O, your data is always <em>on your cluster</em> (in my case, my laptop, but it could be your big server in the basement). Flow uses the browser for display, but it's not pinging a server – it's all hosted locally (hence <code>localhost</code>!). So you don't need to worry about data being intercepted or anything.</p>
<div id="comparison-randomforest-and-caret" class="section level3">
<h3>Comparison: randomForest and caret</h3>
<p>Going back to our random-forest random forest from earlier, we can set up the R equivalent of the H2O forest using the <code>randomForest</code> and <code>caret</code>packages. Specifically, <code>caret</code> is great for dealing with the ML process as a whole – splitting data, managing cross-validation etc. – and in this case it uses <code>randomForest</code> to actually train a classifier.</p>
<p>I'm putting the code for this into a little function called <code>do_rf</code>: it just records the time taken to set up and train the forest, and then returns this time along with performance metrics for the forest.</p>
<pre class="r"><code>do_rf <- function(ntrees, nfolds) {

# Record time at start
start <- Sys.time()

# Make/train the forest
library(caret)
set.seed(820)

caret_split <- createDataPartition(covtype$X55, p = 0.75, list = FALSE, times = 1)

rf <- train(X55 ~ ., data = covtype[caret_split, ],
trControl = trainControl(method = "cv", number = 2),
method = "rf", ntree = ntrees)

# Stop the clock
exec_time <- Sys.time() - start

# Make predictions
preds <- predict(rf, covtype[-caret_split, ])

# Return runtime and performance metrics
list(exec_time, confusionMatrix(preds, covtype$X55[-caret_split]))
}</code></pre>
<p>Technically, cross-validation isn't really necessary for a random forest, since the algorithm isn't prone to overfitting. However, it's a useful example to show how the entire ML workflow is integrated into H2O (using cross-validation is as simple as setting the <code>nfolds</code> parameter), whereas in R you really need to use a "meta"-ML package such as <code>caret</code> or <code>mlr</code> to set up ML projects.</p>
<p>Let's run the <code>do_rf</code> function and see what happens. We'll use 10 trees and 2-fold cross-validation.</p>
<pre class="r"><code>do_rf(ntrees = 10, nfolds = 2)</code></pre>
<pre><code>## [[1]]
## Time difference of 7.788886 mins
## 
## [[2]]
## Confusion Matrix and Statistics
## 
## Reference
## Prediction 1 2 3 4 5 6 7
## 1 50591 1564 1 0 29 11 200
## 2 2208 68905 128 0 352 93 31
## 3 2 119 8576 80 30 243 0
## 4 0 0 43 583 0 18 0
## 5 26 126 14 0 1955 4 2
## 6 4 85 176 23 7 3972 0
## 7 129 26 0 0 0 0 4894
## 
## Overall Statistics
## 
## Accuracy : 0.9602 
## 95% CI : (0.9592, 0.9612)
## [... some more stats]</code></pre>
<p>Performance is reasonably good – according to the UCI website a simple backprop neural net achieved only 70% accuracy on this dataset, so we're well above that.</p>
<p>We can compare this with the performance of the H2O forest by writing a similar <code>do_h2o</code> function containing the code from earlier, then running this function and looking at the results.</p>
<pre class="r"><code>h2o_results <- do_h2o(ntrees = 10, nfolds = 2)</code></pre>
<pre class="r"><code>print(h2o_results)</code></pre>
<pre><code>## [[1]]
## Time difference of 4.436078 mins
## 
## [[2]]
## H2OMultinomialMetrics: drf
## 
## Test Set Metrics: 
## =====================
## 
## MSE: (Extract with `h2o.mse`) 0.09325105
## RMSE: (Extract with `h2o.rmse`) 0.3053703
## Logloss: (Extract with `h2o.logloss`) 0.3262433
## Mean Per-Class Error: 0.183704
## Confusion Matrix: Extract with `h2o.confusionMatrix(<model>, <data>)`)
## =========================================================================
## Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
## 1 2 3 4 5 6 7 Error Rate
## 1 45661 6932 8 0 8 4 112 0.1340 = 7,064 / 52,725
## 2 2887 67758 188 2 55 71 22 0.0454 = 3,225 / 70,983
## 3 0 438 8284 16 0 141 0 0.0670 = 595 / 8,879
## 4 0 0 133 558 0 22 0 0.2174 = 155 / 713
## 5 38 1143 38 0 1147 3 0 0.5158 = 1,222 / 2,369
## 6 7 357 499 24 1 3503 0 0.2022 = 888 / 4,391
## 7 507 22 0 0 0 0 4555 0.1041 = 529 / 5,084
## Totals 49100 76650 9150 600 1211 3744 4689 0.0942 = 13,678 / 145,144
## 
## Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>, <data>)`
## =======================================================================
## Top-7 Hit Ratios: 
## k hit_ratio
## 1 1 0.905763
## 2 2 0.994791
## 3 3 0.999290
## 4 4 0.999862
## 5 5 0.999972
## 6 6 0.999986
## 7 7 1.000000</code></pre>
<p>It turns out that <em>in this case</em>, H2O is faster than R, but the performance is actually worse. <em>In. This. Case.</em> This is <em>not</em> a solid benchmarking test, and of course it would be possible to improve the performance of both of the implementations through some parameter adjustment, but I'm not going to dive into all that. This is just a paddle, remember.</p>
</div>
<div id="comparison-sparklyr" class="section level3">
<h3>Comparison: sparklyr</h3>
<p>Perhaps the best-known ML platform is Apache Spark, and seeing as there's an R package to interface with it – <code>sparklyr</code> – I thought I'd take a brief tangent in order to try it out.</p>
<p>It turned out I was being a bit optimistic. It took me about 10 minutes to set up the H2O random forest for the first time; it took a few hours and lots of yelling at incomprehensible Java-related error messages before I managed to get compatible versions of Spark and Java configured correctly. In fairness this was probably more my fault than Spark’s…</p>
<p>Once it was finally set up, the ML process was quite similar to H2O (although I must admit that initially I found the syntax a little more difficult to get my head around).</p>
<pre class="r"><code>library(sparklyr)
library(dplyr)

sc <- spark_connect(master = "local", version = "2.0.0")

spark_read_csv(sc, "spark_covtype", "covtype.csv", header = FALSE)

covtype_tbl <- tbl(sc, "spark_covtype")

partition <- sdf_partition(covtype_tbl, train = 0.75, test = 0.25, seed = 820)
train_tbl <- partition$train
test_tbl <- partition$test

ml_rf <- ml_random_forest(train_tbl, V55 ~ ., max.depth = 20, max_bins = 32,
num.trees = 20,
type = "classification")

preds <- sdf_predict(ml_rf, test_tbl)

ml_classification_eval(preds, "V55", "prediction", "accuracy")</code></pre>
<pre><code>## [1] 0.8295277</code></pre>
<p>At the time of writing there is no facility in <code>sparklyr</code> for cross-validation. Having said that, the Spark MLlib library <em>does</em> include cross-validation, and <code>sparklyr</code> is still under active development, so this is something which may be added in future.</p>
<p>Running a <code>do_spark(ntrees = 10)</code> function reveals a faster time but much lower accuracy than either R or H2O, but this isn't surprising given that we're not using cross-validation so we're doing less than half the work.</p>
<div id="results-comparison" class="section level4">
<h4>Results comparison</h4>
<table class="table table-condensed"><thead><tr class="header"><th align="left"></th>
<th align="right">Accuracy</th>
<th align="right">Time (mins)</th>
</tr></thead><tbody><tr class="odd"><td align="left"><code>randomForest</code> and <code>caret</code></td>
<td align="right">0.960</td>
<td align="right">7.8</td>
</tr><tr class="even"><td align="left"><code>h2o</code></td>
<td align="right">0.906</td>
<td align="right">4.4</td>
</tr><tr class="odd"><td align="left"><code>sparklyr</code> <em>(no X-val)</em></td>
<td align="right">0.830</td>
<td align="right">1.9</td>
</tr></tbody></table></div>
<p><span style="font-size: 24px;font-weight: bold">Conversion with rsparkling</span></p>
<div id="conversion-with-rsparkling" class="section level3">
<p>If your dataset is already sitting in Spark (or you’re accessing it using Spark) and you want to use H2O's algorithms on it, c'est possible. The <code>rsparkling</code>package allows you to convert a Spark frame to an H2OFrame, which you can then attack with <code>h2o</code>'s functions (e.g. you can take advantage of H2O’s cross-validation).</p>
<pre class="r"><code>library(rsparkling)

options(rsparkling.sparklingwater.version = "2.0.11")

sc <- spark_connect("local", version = "2.0.0")

rsp_train <- as_h2o_frame(sc, train_tbl, strict_version_check = FALSE)
rsp_test <- as_h2o_frame(sc, test_tbl, strict_version_check = FALSE)

rsp_rf <- h2o.randomForest(y = 55, training_frame = rsp_train,
nfolds = 2, ntrees = 10)</code></pre>
<p>Right, we've been talking about random forests for quite a long time now. I'd say we're certainly in over our knees, and by my definition that means we're wading, not paddling. So I'm going to move on to a new algorithm and a new dataset.</p>
</div>
<p><span style="font-size: 29px;font-weight: bold">Demo: Neural nets for MNIST</span></p>
<div id="demo-neural-nets-for-mnist" class="section level2">
<p>Time for a real classic – according to Kaggle, the de facto "hello world" dataset of computer vision. The MNIST dataset is a collection of 60000 images of handwritten digits. Each image is 28×28 pixels in size, and is represented by a 28×28 matrix of values representing the intensity of each pixel.</p>
<p><img class="alignnone size-full wp-image-4003" src="https://mango-solutions.com/assets/sites/6/2018/01/Image5-1.png" alt="" width="640" height="252" srcset="https://www.mango-solutions.com/assets/sites/6/2018/01/Image5-1.png 640w,https://www.mango-solutions.com/assets/sites/6/2018/01/Image5-1-300x118.png 300w" sizes="(max-width: 640px) 100vw, 640px"></p>
<div id="demo-neural-nets-for-mnist" class="section level2">
<p>This matrix is then "unrolled", row by row, into a 784-length vector; and these vectors can be used to train a neural network to classify new images.</p>
<h3><span style="color: inherit;font-size: inherit;font-weight: bold">nnet</span></h3>
<div id="nnet" class="section level3">
<p>First let's get our data into R and create a split for training and test sets.</p>
<pre class="r"><code>library(dplyr)
library(caret)

train <- readr::read_csv("~/H2O_exploration/train.csv") %>%
# Make the label a factor
mutate(label = as.factor(label)) %>%
# Pixel intensities are currently on 0-255 scale;
# rescale on 0-1 by dividing by 255
mutate_if(is.numeric, funs(./255))

set.seed(528491)
part <- createDataPartition(1:nrow(train), p = 0.75, list = FALSE)</code></pre>
<p>The <code>nnet</code> package comes as part of the standard R installation and can be used to set up a simple feed-forward neural network. Here we'll use a 25-unit hidden layer, and we'll stop optimising after 100 iterations if we haven't already run out of steam by then.</p>
<p>As before, we can wrap this code in a little timer function:</p>
<pre class="r"><code>library(nnet)

do_rnet <- function() {

start <- Sys.time()

# Predict label based on all other features (i.e. all the pixels)
# We have to set a high MaxNWts to avoid a memory error
rnet <- nnet(label ~ ., data = train, subset = part,
size = 25, maxit = 100, MaxNWts = 20000)

exec_time <- Sys.time() - start

preds <- predict(rnet, train[-part, -1], type = "class")

list(exec_time, confusionMatrix(preds, train$label[-part]))
}

do_rnet()</code></pre>
<pre><code>## [[1]]
## Time difference of 33.20143 mins
## 
## [[2]]
## Confusion Matrix and Statistics
## 
## Reference
## Prediction 0 1 2 3 4 5 6 7 8 9
## 0 977 0 8 7 2 15 9 3 4 3
## 1 0 1093 5 3 5 1 0 3 11 2
## 2 4 10 977 17 7 5 11 15 7 3
## 3 5 7 23 982 5 29 2 8 26 8
## 4 1 3 7 0 964 1 5 8 2 33
## 5 8 4 4 19 3 880 14 6 9 7
## 6 4 0 3 3 11 14 999 1 7 1
## 7 0 5 7 14 9 4 2 1025 3 20
## 8 9 8 8 20 2 19 7 6 937 9
## 9 4 2 3 13 32 11 1 17 7 973
## 
## Overall Statistics
## 
## Accuracy : 0.934 
## 95% CI : (0.9291, 0.9387)
## [... etc.]</code></pre>
<p>The accuracy ain't much to shout about – the top MNIST classifiers nowadays are well above 99% – but it isn't too bad for such a small implementation. It takes a little while to get there though.</p>
</div>
<p><span style="font-size: 24px;font-weight: bold">H2O</span></p>
<div id="h2o" class="section level3">
<p>Let's see how H2O's implementation compares (they follow the relatively recent trend of calling neural networks "deep learning" classifiers). Note that we're using the same setup here as we did for <code>nnet</code>, i.e. one hidden layer of 25 units, although I couldn't figure out how to limit the number of steps. Also note that the syntax is almost identical to when we implemented the random forest earlier; we've just swapped out <code>randomForest</code> for <code>deeplearning</code>.</p>
<pre class="r"><code>do_h2o_net <- function() {nnet

start <- Sys.time()

library(h2o)
h2o.init()

wetter <- as.h2o(train)
wetter_split <- h2o.splitFrame(wetter, ratios = 0.75, seed = 528491)

h2o_net <- h2o.deeplearning(
x = 2:785,
y = 1,
training_frame = wetter_split[[1]],
hidden = 25
)

exec_time <- Sys.time() - start

list(exec_time, h2o.performance(h2o_net, wetter_split[[2]]))
}

results <- do_h2o_net()
results</code></pre>
<pre><code>## [[1]]
## Time difference of 1.802627 mins
## 
## [[2]]
## H2OMultinomialMetrics: deeplearning
## 
## Test Set Metrics: 
## =====================
## 
## MSE: (Extract with `h2o.mse`) 0.0657653
## RMSE: (Extract with `h2o.rmse`) 0.2564475
## Logloss: (Extract with `h2o.logloss`) 0.5847708
## Mean Per-Class Error: 0.07453935
## Confusion Matrix: Extract with `h2o.confusionMatrix(<model>, <data>)`)
## =========================================================================
## Confusion Matrix: Row labels: Actual class; Column labels: Predicted class
## 0 1 2 3 4 5 6 7 8 9 Error
## 0 1029 0 1 5 3 6 4 5 6 5 0.0329
## 1 0 1189 2 6 3 1 3 1 5 0 0.0174
## 2 8 12 967 17 6 4 15 16 13 2 0.0877
## 3 1 6 25 1005 1 51 3 16 16 8 0.1122
## 4 4 6 9 1 976 1 3 9 2 31 0.0633
## 5 3 5 6 38 5 844 19 2 19 6 0.1088
## 6 7 5 6 2 8 14 971 2 11 0 0.0536
## 7 5 2 15 9 5 4 3 1010 2 23 0.0631
## 8 2 27 5 23 7 15 7 4 929 8 0.0954
## 9 10 2 4 7 36 13 2 35 5 913 0.1110
## Totals 1069 1254 1040 1113 1050 953 1030 1100 1008 996 0.0735
## Rate
## 0 = 35 / 1,064
## 1 = 21 / 1,210
## 2 = 93 / 1,060
## 3 = 127 / 1,132
## 4 = 66 / 1,042
## 5 = 103 / 947
## 6 = 55 / 1,026
## 7 = 68 / 1,078
## 8 = 98 / 1,027
## 9 = 114 / 1,027
## Totals = 780 / 10,613
## 
## Hit Ratio Table: Extract with `h2o.hit_ratio_table(<model>, <data>)`
## =======================================================================
## Top-10 Hit Ratios: 
## k hit_ratio
## 1 1 0.926505
## 2 2 0.972581
## 3 3 0.985490
## 4 4 0.992556
## 5 5 0.995006
## 6 6 0.996608
## 7 7 0.998116
## 8 8 0.998775
## 9 9 0.999152
## 10 10 1.000000</code></pre>
<p>Woah! The accuracy is virtually identical, but we manage it in under 2 minutes, rather than over half an hour.</p>
<p>Just for the sake of it, I also ran a TensorFlow convolutional neural net in Python to see how performance compared. The accuracy was higher than both of the previous implementations and the training process was nearly as fast as H2O had been. However, an upgraded H2O net with two 50-unit hidden layers (as simple as swapping out <code>hidden = 25</code> for <code>hidden = c(50, 50)</code> in the previous code) surpassed even the convnet, both in terms of accuracy and speed.</p>
<p><span style="font-size: 20px;font-weight: bold">Neural nets: results comparison</span></p>
</div>
<div id="neural-nets-results-comparison" class="section level4">
<table class="table table-condensed"><thead><tr class="header"><th></th>
<th align="right"></th>
<th align="right">Accuracy</th>
<th align="right">Time (mins)</th>
</tr></thead><tbody><tr class="odd"><td>nnet</td>
<td align="right">(100 steps, 25 hidden units)</td>
<td align="right">0.934</td>
<td align="right">33.0</td>
</tr><tr class="even"><td>H2O deeplearning</td>
<td align="right">(??? steps, 25 hidden units)</td>
<td align="right">0.927</td>
<td align="right">1.8</td>
</tr><tr class="odd"><td>TensorFlow</td>
<td align="right">(500 steps, 2*conv/relu/FC)</td>
<td align="right">0.950</td>
<td align="right">3.7</td>
</tr><tr class="even"><td>H2O deeplearning</td>
<td align="right">(??? steps, 2*50 hidden units)</td>
<td align="right">0.956</td>
<td align="right">2.2</td>
</tr></tbody></table></div>
<p>There's another slightly subtle point here, but it's a very important one. Notice that when we increase the complexity of the H2O net, the impact on training time is very small.</p>
<p>However, swapping one 25-unit hidden layer for two 50-unit hidden layers means a <em>massive</em> increase in computational complexity. It's not just because we have 4 times the number of neurons; that extra hidden layer means another stage of backpropagation, which is very computationally expensive. So actually, from the relatively small increase in training time, we see that the ML process scales very well (for this medium-sized dataset at least) and we can infer that a large chunk of those 2 minutes is in fact spent on data conversion.</p>
</div>
<h2>H2O or H2No?</h2>
<div id="h2o-or-h2no" class="section level2">
<p>So, should you consider using H2O for <em>your</em> ML applications? Let's review what we've discovered.</p>
<div id="h2pros" class="section level4">
<h4>H2Pros</h4>
<ul><li><strong>Multiple interfaces available.</strong> If you use R or Python you can seamlessly integrate it into your existing workflows.</li>
<li><strong>Intuitive to use.</strong> The R interface uses sensible, memorable function names. The Flow interface guides you through the process and shows you <em>e v e r y t h i n g</em>.</li>
<li><strong>ML scales very well.</strong> More data? No problem. Complicated algorithm? No problem.</li>
<li><strong>Fine control is possible.</strong> Loads of parameters to fiddle around with. Flow shows you exactly what they are. If the "Advanced" ones aren't hard-core enough for you, there's an "Expert" section too.</li>
<li><strong>Integrated ML workflow.</strong> (<code>sparklyr</code>, we're waiting!)</li>
</ul><div id="h2woes" class="section level4">
<h4>H2Woes</h4>
<ul><li><strong>Limited selection of algorithms.</strong> I mean, "limited" here is relative. If you need to use Gaussian mixtures or your application desperately requires Latent Dirichlet Allocation, you'd better head on over to Spark. But H2O covers most things you are likely to use on a regular basis.</li>
<li><strong>Data conversion can be H2Slow.</strong> But again, this is relative. If you have to spend 2 minutes converting your data to an H2OFrame, but this saves you 30 minutes of algorithm runtime, you're probably prepared to do it!</li>
<li><strong>Some algorithms are black box methods.</strong> But... Â¯\_(?)_/Â¯. The algorithms which are "black-box" are still black-box whichever implementation you're using, so this probably isn't a downside to H2O per se – it's more of a general ML "problem" (whether it's an actual problem often depends on your point of view). And H2O is open source, so if you want to you can go and dig around in the <a href="https://github.com/h2oai/h2o-3">source code</a>.</li>
</ul><p>So if you're looking for a way to speed up your ML training times by replacing R algorithm implementations, in my opinion H2O is a great choice of ML framework.</p>
</div>
<h2>Bon voyage!</h2>
<div id="bon-voyage" class="section level2">
<p>I might have mentioned once or twice that this was just a paddle (sorry if you're bored of the theme, but I promise I'm nearly done!). I really have only touched on the basics here: there's <em>loads</em> more to H2O than what I've covered in this post. If you're interested in GPU-based deep learning, you might want to go and read about <a href="https://www.h2o.ai/deep-water/">Deep Water</a>. If Spark and H2O sounds like a super combination, check out <a href="https://www.h2o.ai/download-2/sparkling-water/">Sparkling Water</a>. If you're keen on producing streamlined data analysis applications, have a look at <a href="https://www.h2o.ai/steam/">Steam</a>. And of course <a href="http://docs.h2o.ai/h2o/latest-stable/index.html">the documentation</a> for H2O, and for all those other H2O.ai enterprises, goes into much greater detail than I possibly could.</p>
<p>Off you go then! It's been fun paddling together, but now I'll leave you to do your own thing. Go and dry off, or carry on frolicking in the waves, or get started training for your 100m freestyle world record attempt. Me? I'm off for an ice cream.</p>
<hr><div id="justme" class="section level2">
<p><a name="justme"></a></p>
<h5>Who is “just me”?</h5>
<p>Hi, I’m Owen. I’m a maths undergraduate at the University of Bath. Just over a year ago I found out about machine learning (and consequently data science), and decided that it looked much more fun than all the other careers I’d been half-heartedly researching up to that point. I’m now a couple of months into a year-long placement at Mango: I’m thoroughly enjoying myself, and given that I haven’t been kicked out yet I assume they don’t mind having me around <em>too</em> much.</p>
<p>If you want to talk about H2O, ML or anything else at all you can reach me by email at ojones@mango-solutions.com, on Twitter @owenjonesuob, or via <a href="https://owenjonesuob.github.io/">my website</a>.</p>
</div>
		<div class="section section-blog-info">
			<div class="row">
				<div class="col-md-6">
					<div class="entry-categories">Categories:						<span class="label label-primary"><a href="https://bathml.github.io/blog/category/technical/">Technical</a></span>					</div>
					<div class="entry-tags">Tags: <span class="entry-tag"><a href="https://bathml.github.io/blog/tag/frameworks/" rel="tag">frameworks</a></span><span class="entry-tag"><a href="https://bathml.github.io/blog/tag/h2o/" rel="tag">h2o</a></span><span class="entry-tag"><a href="https://bathml.github.io/blog/tag/machinelearning/" rel="tag">machinelearning</a></span><span class="entry-tag"><a href="https://bathml.github.io/blog/tag/neuralnets/" rel="tag">neuralnets</a></span><span class="entry-tag"><a href="https://bathml.github.io/blog/tag/randomforest/" rel="tag">randomforest</a></span></div>				</div>
				
        <div class="col-md-6">
            <div class="entry-social">
                <a target="_blank" rel="tooltip" data-original-title="Share on Facebook" class="btn btn-just-icon btn-round btn-facebook" href="https://www.facebook.com/sharer.php?u=https://bathml.github.io/blog/h2o-ai-going-for-a-paddle/">
                   <i class="fab fa-facebook-f"></i>
                </a>
                
                <a target="_blank" rel="tooltip" data-original-title="Share on Twitter" class="btn btn-just-icon btn-round btn-twitter" href="http://twitter.com/share?url=https://bathml.github.io/blog/h2o-ai-going-for-a-paddle/&text=H2O.ai%3A%20Going%20for%20a%20Paddle">
                   <i class="fab fa-twitter"></i>
                </a>
                
                <a rel="tooltip" data-original-title=" Share on Email" class="btn btn-just-icon btn-round" href="mailto:?subject=H2O.ai:%20Going%20for%20a%20Paddle&body=https://bathml.github.io/blog/h2o-ai-going-for-a-paddle/">
                   <i class="fas fa-envelope"></i>
               </a>
            </div>
		</div>			</div>
			<hr></div>
		</div>		</div>


		</div>
	</div>
</div>

<div class="footer-wrapper">
						<footer class="footer footer-black footer-big"><div class="container">
																<div class="hestia-bottom-footer-content"><ul class="footer-menu pull-left"><li class="page_item page-item-19 current_page_parent"><a href="https://bathml.github.io/blog/">Blog</a></li>
<li class="page_item page-item-18"><a href="https://bathml.github.io/contact/">Contact</a></li>
<li class="page_item page-item-23"><a href="https://bathml.github.io/events/">Events</a></li>
<li class="page_item page-item-16"><a href="https://bathml.github.io/">Home</a></li>
<li class="page_item page-item-60"><a href="https://bathml.github.io/sponsors/">Sponsors</a></li>
</ul><div class="copyright pull-right">
				Hestia | Developed by <a href="https://themeisle.com" rel="nofollow">ThemeIsle</a>			</div>
			</div>			</div>
					</footer></div>
	</div>
<script type="text/javascript" src="https://bathml.github.io/themes/hestia/assets/bootstrap/js/bootstrap.min.js"></script><script type="text/javascript" src="https://bathml.github.io/inc/js/jquery/ui/core.min.js"></script><script type="text/javascript">
/* <![CDATA[ */
var requestpost = {"ajaxurl":"https:\/\/bathml.github.io\/wp-admin\/admin-ajax.php","disable_autoslide":"","masonry":""};
/* ]]> */
</script><script type="text/javascript" src="https://bathml.github.io/themes/hestia/assets/js/script.min.js"></script></div></div></div></div></div></div></div></article></div></div></div></div></body></html>
